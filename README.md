ORPO is a new exciting fine-tuning technique that combines the traditional supervised fine-tuning and preference alignment stages into a single process. This reduces the computational resources and time required for training. 
Moreover, empirical results demonstrate that ORPO outperforms other alignment methods on various model sizes and benchmarks.

This notebook can be used to fine-tune the Llama 3 8B model using ORPO with the TRL library.
